{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5602f098",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1372\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'E:\\\\Dev VS\\\\pyenvs\\\\fastapi\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\data\\\\experimental\\\\service'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Reshape, Flatten, Dropout\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization, Activation, ZeroPadding2D\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LeakyReLU\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:95\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:387\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mE:\\Dev VS\\pyenvs\\fastapi\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1408\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1374\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[1;34m(cls, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1350\u001b[0m, in \u001b[0;36m_path_hooks\u001b[1;34m(path)\u001b[0m\n",
      "File \u001b[1;32m<frozen zipimport>:76\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, path)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.activation import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d70729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Conv2D(32, kernel_size=3, strides=2, input_shape=(28, 28, 1), padding=\"same\"))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "    discriminator.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    discriminator.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "    discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "    discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    discriminator.summary()\n",
    "    img = Input(shape=(28, 28, 1))\n",
    "    probability = discriminator(img)\n",
    "    return Model(inputs=img, outputs=probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(64 * 28 * 28, activation=\"relu\", input_dim=100))\n",
    "    generator.add(Reshape((28, 28, 64)))\n",
    "    generator.add(Conv2D(64, kernel_size=3, padding=\"same\", strides=(1,1),\n",
    "                         activation=\"relu\"))\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2D(32, kernel_size=3, padding=\"same\",\n",
    "                         activation=\"relu\"))\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2D(1, kernel_size=3, padding=\"same\",\n",
    "                         activation=\"relu\"))\n",
    "    generator.summary()\n",
    "    noise = Input(shape=(100,))\n",
    "    fake_image = generator(noise)\n",
    "    return Model(inputs=noise, outputs=fake_image)\n",
    "\n",
    "build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_input(img, ax):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    width, height = img.shape\n",
    "    thresh = img.max() / 2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(round(img[x][y], 2)), xy=(y, x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y] < thresh else 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5cadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, discriminator_epochs, batch_size=64, save_interval=50):\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "    for epoch in range(discriminator_epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        print(\"%d [D loss: %f, acc.: %.2f%%] \" % (epoch, d_loss[0], 100 * d_loss[1]))\n",
    "    for epoch in range(epochs):\n",
    "        # Train the combined network (Generator)\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "        print(\"%d [G loss: %f]\" % (epoch, g_loss))\n",
    "        if epoch % save_interval == 0:\n",
    "            plot_generated_images(epoch, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=64, save_interval=50):\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    for epoch in range(epochs):\n",
    "        # Train Discriminator network\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        dim = (10,10)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        # Train the combined network (Generator)\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "        print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "        if epoch % save_interval == 0:\n",
    "            for i in range(gen_imgs.shape[0]):\n",
    "                plt.subplot(dim[0], dim[1], i + 1)\n",
    "                plt.imshow(gen_imgs[i], interpolation='nearest', cmap='gray_r')\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "            for i in range(gen_imgs.shape[0], gen_imgs.shape[0] + imgs.shape[0]):\n",
    "                plt.subplot(dim[0], dim[1], i + 1)\n",
    "                plt.imshow(imgs[i-gen_imgs.shape[0]], interpolation='nearest', cmap='gray_r')\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "            plt.savefig('gen_images/train_compare_image_epoch_%d.png' % epoch)\n",
    "            plot_generated_images(epoch, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e054e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(\n",
    "        epoch, generator, examples=100, dim=(10, 10),\n",
    "        figsize=(10, 10)):\n",
    "    latent_dim = 100\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest',\n",
    "               cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.savefig('gen_images/gan_generated_image_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010c56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data = np.load('../datasets/full_numpy_bitmap_smiley face.npy')\n",
    "# training_data = np.array([np.array_split(img_arr, 28) for img_arr in training_data])\n",
    "training_data = training_data.reshape(training_data.shape[0], 28, 28).astype(\n",
    "    \"float32\"\n",
    ") / 127.5 - 1.0\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "visualize_input(training_data[0], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4169b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (training_data, _), (_, _) = fashion_mnist.load_data()\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# ax = fig.add_subplot(111)\n",
    "# visualize_input(training_data[0], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9638c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train = training_data / 255.0\n",
    "X_train = training_data\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "disc_optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=disc_optimizer, metrics=['accuracy'])\n",
    "discriminator.trainable = False\n",
    "generator = build_generator()\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "valid = discriminator(img)\n",
    "combined = Model(inputs=z, outputs=valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2aa499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8d832",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(1000, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9006c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_generated_images(999999, generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
